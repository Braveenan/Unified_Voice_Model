{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "029f70e0-b3a5-4492-9f24-1ecaf6f0e430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import pandas as pd\n",
    "from dataset.create_all_embedding import *\n",
    "from utils.constant_mapping import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "744cc37f-7dbf-4e61-8c8a-2aefaa485364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_size(file_path):\n",
    "    \"\"\"\n",
    "    Get and print the size of a file.\n",
    "\n",
    "    :param file_path: The path to the file.\n",
    "    \"\"\"\n",
    "    if os.path.exists(file_path):\n",
    "        # Get the size of the file in bytes\n",
    "        file_size_bytes = os.path.getsize(file_path)\n",
    "\n",
    "        # Convert the size to a more human-readable format (e.g., KB, MB, GB, etc.)\n",
    "        def convert_size(size_bytes):\n",
    "            if size_bytes == 0:\n",
    "                return \"0 B\"\n",
    "            size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "            i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "            p = math.pow(1024, i)\n",
    "            s = round(size_bytes / p, 2)\n",
    "            return f\"{s} {size_name[i]}\"\n",
    "\n",
    "        # Call the function to convert the file size and print it\n",
    "        file_size_readable = convert_size(file_size_bytes)\n",
    "        return file_size_readable\n",
    "    else:\n",
    "        return \"does not exist\"\n",
    "    \n",
    "def set_device(device_index=None):\n",
    "    if device_index is not None and torch.cuda.is_available():\n",
    "        num_devices = torch.cuda.device_count()\n",
    "        if num_devices > device_index:\n",
    "            torch.cuda.set_device(device_index)\n",
    "            device = torch.device(\"cuda\")\n",
    "            print(f\"Using GPU {torch.cuda.current_device()}\")\n",
    "            return device\n",
    "        else:\n",
    "            torch.cuda.set_device(0)\n",
    "            device = torch.device(\"cuda:0\")\n",
    "            print(\"Specified GPU index is out of range. Using the first GPU.\")\n",
    "            return device\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"CUDA is not available or GPU index is not specified. Using CPU.\")\n",
    "        return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3209490c-0002-4a8f-a53d-930e7e76c00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU 0\n"
     ]
    }
   ],
   "source": [
    "root_path = \"/home/braveenan/voice_dataset\"\n",
    "root_speechcommand = os.path.join(root_path, \"SpeechCommand\")\n",
    "root_voxceleb = os.path.join(root_path, \"VoxCeleb\")\n",
    "root_iemocap = os.path.join(root_path, \"IEMOCAP\")\n",
    "\n",
    "device = set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "539787cb-f658-46cf-b2f9-ae500992033f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upstream model type: wavlm_large\n",
      "Frame pooling type: energy\n"
     ]
    }
   ],
   "source": [
    "# Specify the model and frame pooling type directly\n",
    "upstream_model_type = \"wavlm_large\"\n",
    "frame_pooling_type = \"energy\"\n",
    "\n",
    "upstreammodel_text = f\"Upstream model type: {upstream_model_type}\"\n",
    "print(upstreammodel_text)\n",
    "frame_pooling_text = f\"Frame pooling type: {frame_pooling_type}\"\n",
    "print(frame_pooling_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "868d7e36-1f5d-4641-bd80-42d68b4b6f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_emb_path = root_path.replace(\"/voice_dataset\", f\"/embedding1/{upstream_model_type}/{frame_pooling_type}\")\n",
    "root_speechcommand_emb = os.path.join(root_emb_path, \"SpeechCommand\")\n",
    "root_voxceleb_emb = os.path.join(root_emb_path, \"VoxCeleb\")\n",
    "root_iemocap_emb = os.path.join(root_emb_path, \"IEMOCAP\")\n",
    "\n",
    "os.makedirs(root_speechcommand_emb, exist_ok=True)\n",
    "os.makedirs(root_voxceleb_emb, exist_ok=True)\n",
    "os.makedirs(root_iemocap_emb, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d355658-8619-4fc3-ae95-ff9bda02675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle = ModelMapping.get_model_bundle(upstream_model_type)\n",
    "upstream_model = bundle.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db4e24d4-a1ff-429d-8853-8efb4f18ebf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of training data samples: 138361 \n",
      "No of validating data samples: 6904 \n",
      "No of testing data samples: 8251\n"
     ]
    }
   ],
   "source": [
    "training_data = VoxCeleb1Embedding (\n",
    "    root=root_voxceleb,\n",
    "    subset = 'train',\n",
    "    download=False,\n",
    "    model=upstream_model,\n",
    "    device=device,\n",
    "    frame_pooling_type=frame_pooling_type,\n",
    ")\n",
    "\n",
    "validating_data = VoxCeleb1Embedding (\n",
    "    root=root_voxceleb,\n",
    "    subset = 'dev',\n",
    "    download=False,\n",
    "    model=upstream_model,\n",
    "    device=device,\n",
    "    frame_pooling_type=frame_pooling_type,\n",
    ")\n",
    "\n",
    "testing_data = VoxCeleb1Embedding (\n",
    "    root=root_voxceleb,\n",
    "    subset = 'test',\n",
    "    download=False,\n",
    "    model=upstream_model,\n",
    "    device=device,\n",
    "    frame_pooling_type=frame_pooling_type,\n",
    ")\n",
    "\n",
    "dataset_length_text = f\"No of training data samples: {len(training_data)} \\nNo of validating data samples: {len(validating_data)} \\nNo of testing data samples: {len(testing_data)}\"\n",
    "print(dataset_length_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a760eee0-b35e-4a3d-a84f-b001adc8bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to process data and write to CSV\n",
    "def process_and_write_data(data, subset, csv_file):\n",
    "    for index, data_point in enumerate(data):\n",
    "        (embedding, emblength, wavlength, label, wavpath) = data_point\n",
    "        duration = wavlength // 16000\n",
    "        embpath = os.path.join(root_voxceleb_emb, wavpath)\n",
    "        embpath = embpath.replace(\".wav\", f\"_{upstream_model_type}_{frame_pooling_type}.pt\")\n",
    "        embdir = embpath.replace(f\"/{embpath.split('/')[-1]}\", \"\")\n",
    "        os.makedirs(embdir, exist_ok=True)\n",
    "        torch.save(embedding, embpath)\n",
    "        file_size_readable = get_file_size(embpath)\n",
    "\n",
    "        # Write the data directly to the CSV file\n",
    "        csv_file.write(f\"{wavpath},{label},{wavlength},{duration},{emblength},{subset},{file_size_readable}\\n\")\n",
    "\n",
    "        print(f\"{subset} {index+1} {wavpath}\")\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbc246b0-87f3-4e5f-bc57-997ecfd27170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1 id10001/1zcIwhmdeo4/00001.wav\n",
      "validation 1 id10001/7w0IBEWc9Qw/00001.wav\n",
      "test 1 id10001/Y8hIVOBuels/00001.wav\n"
     ]
    }
   ],
   "source": [
    "# Create and open the CSV file for writing\n",
    "output_csv_file = os.path.join(root_voxceleb_emb, f\"voxceleb_{upstream_model_type}_{frame_pooling_type}.csv\")\n",
    "with open(output_csv_file, 'w') as csv_file:\n",
    "    csv_file.write(\"Audio path,Audio label,Audio length,Audio duration,Sequence length,Data subset, File size\\n\")\n",
    "\n",
    "    process_and_write_data(training_data, \"train\", csv_file)\n",
    "    process_and_write_data(validating_data, \"validation\", csv_file)\n",
    "    process_and_write_data(testing_data, \"test\", csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95da5e5a-ccae-4255-bc86-ff52df98e0bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before empty_cache - Allocated: 1.2704 GB, Cached: 2.0133 GB\n",
      "After empty_cache - Allocated: 1.2704 GB, Cached: 1.3191 GB\n"
     ]
    }
   ],
   "source": [
    "# Display GPU memory usage before and after emptying the cache\n",
    "allocated_before = torch.cuda.memory_allocated() / 1e9  # convert to GB\n",
    "cached_before = torch.cuda.memory_reserved() / 1e9  # convert to GB\n",
    "print(f\"Before empty_cache - Allocated: {allocated_before:.4f} GB, Cached: {cached_before:.4f} GB\")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "allocated_after = torch.cuda.memory_allocated() / 1e9  # convert to GB\n",
    "cached_after = torch.cuda.memory_reserved() / 1e9  # convert to GB\n",
    "print(f\"After empty_cache - Allocated: {allocated_after:.4f} GB, Cached: {cached_after:.4f} GB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
