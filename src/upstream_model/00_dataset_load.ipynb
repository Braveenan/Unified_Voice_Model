{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7c9c671-b6a3-4e5d-b69a-42117d03d0c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "from torchaudio.datasets import SPEECHCOMMANDS, VoxCeleb1Identification, IEMOCAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7faf57e-f630-432c-bb9f-2fc649c4cc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/home/braveenan/voice_dataset\"\n",
    "root_speechcommand = os.path.join(root_path, \"SpeechCommand\")\n",
    "root_voxceleb = os.path.join(root_path, \"VoxCeleb\")\n",
    "root_iemocap = os.path.join(root_path, \"IEMOCAP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a46348f-9759-4d18-aad2-51669dfdc777",
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle = torchaudio.pipelines.WAVLM_LARGE\n",
    "upstream_model = bundle.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a027a078-b75b-4f4d-a89f-77a915af530f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64721\n",
      "(tensor([[ 9.1553e-05,  3.0518e-05,  1.8311e-04,  ..., -3.0518e-05,\n",
      "         -9.1553e-05,  1.2207e-04]]), 16000, 'bed', '00176480', 0)\n"
     ]
    }
   ],
   "source": [
    "sc_train = SPEECHCOMMANDS(root=root_speechcommand, url = \"speech_commands_v0.01\", download=False, subset=\"training\")\n",
    "sc_val = SPEECHCOMMANDS(root=root_speechcommand, url = \"speech_commands_v0.01\", download=False, subset=\"validation\")\n",
    "sc_test = SPEECHCOMMANDS(root=root_speechcommand, url = \"speech_commands_v0.01\", download=False, subset=\"testing\")\n",
    "print(len(sc_train)+len(sc_val)+len(sc_test))\n",
    "print(sc_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b421bdf5-2887-4049-b265-c8a03af8c343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 49, 1024])\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    waveform = sc_train[0][0]\n",
    "    output = upstream_model.forward(waveform)\n",
    "    features, _ = upstream_model.extract_features(waveform)\n",
    "    \n",
    "print(output[0].shape)\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e95e0a07-9c18-44f6-b9d7-c424494849cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153516\n",
      "(tensor([[ 0.0703,  0.0703,  0.0916,  ..., -0.0863, -0.1171, -0.1537]]), 16000, 1, 'id10001-1zcIwhmdeo4-00001')\n"
     ]
    }
   ],
   "source": [
    "vc_train = VoxCeleb1Identification(root=root_voxceleb, download=False, subset=\"train\")\n",
    "vc_val = VoxCeleb1Identification(root=root_voxceleb, download=False, subset=\"dev\")\n",
    "vc_test = VoxCeleb1Identification(root=root_voxceleb, download=False, subset=\"test\")\n",
    "print(len(vc_train)+len(vc_val)+len(vc_test))\n",
    "print(vc_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b547e9f-b5b9-4b37-99fc-ce6cbb36eae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 405, 1024])\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    waveform = vc_train[0][0]\n",
    "    output = upstream_model.forward(waveform)\n",
    "    features, _ = upstream_model.extract_features(waveform)\n",
    "    \n",
    "print(output[0].shape)\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73684689-6908-4522-b230-9bccaf77ebf1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7380\n",
      "(tensor([[-0.0050, -0.0050, -0.0038,  ..., -0.0027, -0.0032, -0.0042]]), 16000, 'Ses01F_impro01_F000', 'neu', 'Ses01F')\n"
     ]
    }
   ],
   "source": [
    "ic_train = IEMOCAP(root = root_iemocap, sessions = (1, 2, 3), utterance_type = None)\n",
    "ic_val = IEMOCAP(root = root_iemocap, sessions = (4,), utterance_type = None)\n",
    "ic_test = IEMOCAP(root = root_iemocap, sessions = (5,), utterance_type = None)\n",
    "print(len(ic_train)+len(ic_val)+len(ic_test))\n",
    "print(ic_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a616c73a-9d97-442b-8222-3ee0a0d68589",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 97, 1024])\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    waveform = ic_train[0][0]\n",
    "    output = upstream_model.forward(waveform)\n",
    "    features, _ = upstream_model.extract_features(waveform)\n",
    "    \n",
    "print(output[0].shape)\n",
    "print(len(features))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
