{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "029f70e0-b3a5-4492-9f24-1ecaf6f0e430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from dataset.create_all_embedding import *\n",
    "from utils.constant_mapping import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c716969b-1be2-420a-91d5-bcfd0fbd675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to calculate model size\n",
    "def get_model_size(model):\n",
    "    # Number of parameters\n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "    # Memory size in bytes\n",
    "    mem_size = sum(p.element_size() * p.numel() for p in model.parameters())\n",
    "    \n",
    "    return num_params, mem_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "320cc666-50ff-4e1b-af21-9c967d10189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to remove Transformer encoder layers and print stats\n",
    "def remove_and_print_stats(model):\n",
    "    # Get the list of Transformer encoder layers\n",
    "    transformer_layers = model.model.encoder.transformer.layers\n",
    "\n",
    "    if isinstance(transformer_layers, nn.ModuleList):\n",
    "        # Initial stats\n",
    "        num_params, mem_size = get_model_size(model)\n",
    "        print(f\"Initial Model - Parameters: {num_params}, Memory Size: {mem_size / (1024 ** 2):.2f} MB\")\n",
    "\n",
    "        # Loop to remove the last layer and print stats\n",
    "        while len(transformer_layers) > 0:\n",
    "            # Remove the last encoder layer\n",
    "            transformer_layers._modules.popitem()  # Use internal method to remove the last module\n",
    "            \n",
    "            # Print stats after removal\n",
    "            num_params, mem_size = get_model_size(model)\n",
    "            print(f\"After Removing Layer {len(transformer_layers)+1} - Parameters: {num_params}, Memory Size: {mem_size / (1024 ** 2):.2f} MB\")\n",
    "    else:\n",
    "        print(\"The transformer_layers is not a nn.ModuleList and cannot be modified with pop.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d355658-8619-4fc3-ae95-ff9bda02675d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "upstream_model_type = \"wavlm_large\"\n",
    "bundle = ModelMapping.get_model_bundle(upstream_model_type)\n",
    "upstream_model = bundle.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97480245-c94c-481b-9c0a-ae6107516a52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Model - Parameters: 315452096, Memory Size: 1203.35 MB\n",
      "After Removing Layer 24 - Parameters: 302855336, Memory Size: 1155.30 MB\n",
      "After Removing Layer 23 - Parameters: 290258576, Memory Size: 1107.25 MB\n",
      "After Removing Layer 22 - Parameters: 277661816, Memory Size: 1059.20 MB\n",
      "After Removing Layer 21 - Parameters: 265065056, Memory Size: 1011.14 MB\n",
      "After Removing Layer 20 - Parameters: 252468296, Memory Size: 963.09 MB\n",
      "After Removing Layer 19 - Parameters: 239871536, Memory Size: 915.04 MB\n",
      "After Removing Layer 18 - Parameters: 227274776, Memory Size: 866.98 MB\n",
      "After Removing Layer 17 - Parameters: 214678016, Memory Size: 818.93 MB\n",
      "After Removing Layer 16 - Parameters: 202081256, Memory Size: 770.88 MB\n",
      "After Removing Layer 15 - Parameters: 189484496, Memory Size: 722.83 MB\n",
      "After Removing Layer 14 - Parameters: 176887736, Memory Size: 674.77 MB\n",
      "After Removing Layer 13 - Parameters: 164290976, Memory Size: 626.72 MB\n",
      "After Removing Layer 12 - Parameters: 151694216, Memory Size: 578.67 MB\n",
      "After Removing Layer 11 - Parameters: 139097456, Memory Size: 530.61 MB\n",
      "After Removing Layer 10 - Parameters: 126500696, Memory Size: 482.56 MB\n",
      "After Removing Layer 9 - Parameters: 113903936, Memory Size: 434.51 MB\n",
      "After Removing Layer 8 - Parameters: 101307176, Memory Size: 386.46 MB\n",
      "After Removing Layer 7 - Parameters: 88710416, Memory Size: 338.40 MB\n",
      "After Removing Layer 6 - Parameters: 76113656, Memory Size: 290.35 MB\n",
      "After Removing Layer 5 - Parameters: 63516896, Memory Size: 242.30 MB\n",
      "After Removing Layer 4 - Parameters: 50920136, Memory Size: 194.24 MB\n",
      "After Removing Layer 3 - Parameters: 38323376, Memory Size: 146.19 MB\n",
      "After Removing Layer 2 - Parameters: 25726616, Memory Size: 98.14 MB\n",
      "After Removing Layer 1 - Parameters: 13124736, Memory Size: 50.07 MB\n"
     ]
    }
   ],
   "source": [
    "remove_and_print_stats(upstream_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e1bbf5-ba48-48a5-92cf-867d62f28faa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
